# =============================================================================
# LangGraph Multi-Agent Configuration
# =============================================================================

# Environment
NODE_ENV=development

# =============================================================================
# PostgreSQL Database Configuration
# =============================================================================
POSTGRES_DB=langgraph
POSTGRES_USER=langgraph
POSTGRES_PASSWORD=langgraph_password
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
PGDATA=/var/lib/postgresql/data/pgdata

# Database URI for LangGraph
DATABASE_URI=postgresql://langgraph:langgraph_password@postgres:5432/langgraph


# =============================================================================
# AI Model Provider Configuration
# =============================================================================

# Model Provider Priority (comma-separated list)
# Available: ollama, openai, anthropic, groq, together
# First available provider in this list will be used as primary
MODEL_PROVIDER_PRIORITY=ollama,openai,anthropic,groq,together

# Global Model Parameters
MODEL_TEMPERATURE=0.7
MODEL_TOP_P=0.9
MODEL_MAX_TOKENS=500

# API Timeouts (for cloud providers)
API_CONNECT_TIMEOUT=10
API_REQUEST_TIMEOUT=60

# =============================================================================
# Ollama Configuration (Local Models)
# =============================================================================
OLLAMA_HOST=ollama
OLLAMA_PORT=11434
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_KEEP_ALIVE=24h
OLLAMA_MODELS=/root/.ollama/models
OLLAMA_MODEL=phi3:mini

# Ollama-specific timeouts and retries
OLLAMA_CONNECT_TIMEOUT=10
OLLAMA_REQUEST_TIMEOUT=180
OLLAMA_RETRY_ATTEMPTS=1
OLLAMA_RETRY_BACKOFF=3

# =============================================================================
# OpenAI Configuration
# =============================================================================
# Uncomment and set your OpenAI API key to enable OpenAI provider
# OPENAI_API_KEY=sk-your-openai-api-key-here
# OPENAI_MODEL=gpt-3.5-turbo
# OPENAI_BASE_URL=https://api.openai.com/v1

# =============================================================================
# Anthropic Configuration
# =============================================================================
# Uncomment and set your Anthropic API key to enable Claude
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
# ANTHROPIC_MODEL=claude-3-haiku-20240307
# ANTHROPIC_BASE_URL=https://api.anthropic.com

# =============================================================================
# Groq Configuration
# =============================================================================
# Uncomment and set your Groq API key to enable Groq
# GROQ_API_KEY=gsk_your-groq-api-key-here
# GROQ_MODEL=llama3-8b-8192
# GROQ_BASE_URL=https://api.groq.com/openai/v1

# =============================================================================
# Together AI Configuration
# =============================================================================
# Uncomment and set your Together AI API key to enable Together AI
# TOGETHER_API_KEY=your-together-api-key-here
# TOGETHER_MODEL=meta-llama/Llama-2-7b-chat-hf
# TOGETHER_BASE_URL=https://api.together.xyz/v1

# =============================================================================
# Legacy Configuration (Backward Compatibility)
# =============================================================================
# These are kept for backward compatibility
LLM_MODEL=phi3:mini

# =============================================================================
# LangGraph Agent Configuration
# =============================================================================
LANGGRAPH_AGENT_PORT=8000

# =============================================================================
# External Ports (Host Machine)
# =============================================================================
POSTGRES_EXTERNAL_PORT=5432
OLLAMA_EXTERNAL_PORT=11434
LANGGRAPH_EXTERNAL_PORT=8000
UI_EXTERNAL_PORT=3000

# =============================================================================
# UI Configuration
# =============================================================================
# The UI container generates /config.js from this value at runtime.
# Default to relative /api and let Nginx proxy to the agent.
UI_API_BASE_URL=/api
