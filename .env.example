# =============================================================================
# LangGraph Multi-Agent Configuration
# =============================================================================

# Environment
NODE_ENV=development

# =============================================================================
# PostgreSQL Database Configuration
# =============================================================================
POSTGRES_DB=langgraph
POSTGRES_USER=langgraph
POSTGRES_PASSWORD=langgraph_password
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
PGDATA=/var/lib/postgresql/data/pgdata

# Database URI for LangGraph
DATABASE_URI=postgresql://langgraph:langgraph_password@postgres:5432/langgraph


# =============================================================================
# AI Model Provider Configuration
# =============================================================================

# Model Provider Priority (comma-separated list)
# Available: ollama, openai, anthropic, groq, together, deepseek
# First available provider in this list will be used as primary
MODEL_PROVIDER_PRIORITY=openai,deepseek,anthropic,groq,together,ollama

# Global Model Parameters
MODEL_TEMPERATURE=0.7
MODEL_TOP_P=0.9
MODEL_MAX_TOKENS=2000

# ReAct Agent Reasoning Settings (applies to all providers)
REACT_REASONING_EFFORT=medium     # Options: minimal, low, medium, high
REACT_VERBOSITY=medium           # Options: low, medium, high  
REACT_USE_THINKING=true          # Enable reasoning for complex tasks

# API Timeouts (for cloud providers)
API_CONNECT_TIMEOUT=10
API_REQUEST_TIMEOUT=60

# =============================================================================
# Ollama Configuration (Local Models)
# =============================================================================
OLLAMA_HOST=ollama
OLLAMA_PORT=11434
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_KEEP_ALIVE=24h
OLLAMA_MODELS=/root/.ollama/models
OLLAMA_MODEL=llama3.2:1b

# Ollama-specific timeouts and retries
OLLAMA_CONNECT_TIMEOUT=10
OLLAMA_REQUEST_TIMEOUT=180
OLLAMA_RETRY_ATTEMPTS=1
OLLAMA_RETRY_BACKOFF=3

# =============================================================================
# OpenAI Configuration (GPT-5 Series - 2025)
# =============================================================================
# Uncomment and set your OpenAI API key to enable OpenAI provider
# OPENAI_API_KEY=sk-your-openai-api-key-here
# OPENAI_MODEL=gpt-5-nano
# OPENAI_BASE_URL=https://api.openai.com/v1

# GPT-5 Reasoning Parameters (built into all GPT-5 models)
# OPENAI_REASONING_EFFORT=minimal   # Options: minimal, low, medium, high
# OPENAI_VERBOSITY=medium          # Options: low, medium, high
# OPENAI_MAX_CONTEXT=400000        # Max 400K tokens input
# OPENAI_MAX_OUTPUT=128000         # Max 128K tokens output

# Alternative GPT-5 Models:
# gpt-5       - $1.25/1M input, $10/1M output (flagship)  
# gpt-5-mini  - $0.25/1M input, $2/1M output (balanced)
# gpt-5-nano  - $0.05/1M input, $0.40/1M output (cheapest, default)

# =============================================================================
# Anthropic Configuration
# =============================================================================
# Uncomment and set your Anthropic API key to enable Claude
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
# ANTHROPIC_MODEL=claude-3-haiku-20240307
# ANTHROPIC_BASE_URL=https://api.anthropic.com

# =============================================================================
# Groq Configuration
# =============================================================================
# Uncomment and set your Groq API key to enable Groq
# GROQ_API_KEY=gsk_your-groq-api-key-here
# GROQ_MODEL=llama3-8b-8192
# GROQ_BASE_URL=https://api.groq.com/openai/v1

# =============================================================================
# Together AI Configuration
# =============================================================================
# Uncomment and set your Together AI API key to enable Together AI
# TOGETHER_API_KEY=your-together-api-key-here
# TOGETHER_MODEL=meta-llama/Llama-2-7b-chat-hf
# TOGETHER_BASE_URL=https://api.together.xyz/v1

# =============================================================================
# DeepSeek Configuration
# =============================================================================
# Uncomment and set your DeepSeek API key to enable DeepSeek
# DEEPSEEK_API_KEY=sk-your-deepseek-api-key-here
# DEEPSEEK_MODEL=deepseek-r1
# DEEPSEEK_BASE_URL=https://api.deepseek.com

# =============================================================================
# Legacy Configuration (Backward Compatibility)
# =============================================================================
# These are kept for backward compatibility
LLM_MODEL=llama3.2:1b

# =============================================================================
# LangGraph ReAct Agent Configuration
# =============================================================================
LANGGRAPH_AGENT_PORT=8000

# ReAct Agent Settings
REACT_MAX_ITERATIONS=5
EMBEDDING_CHUNK_SIZE=1000
EMBEDDING_CHUNK_OVERLAP=200

# Embedding Configuration (for document search)
# OPENAI_EMBEDDING_MODEL=text-embedding-ada-002

# =============================================================================
# External Ports (Host Machine)
# =============================================================================
POSTGRES_EXTERNAL_PORT=5432
OLLAMA_EXTERNAL_PORT=11434
LANGGRAPH_EXTERNAL_PORT=8000
UI_EXTERNAL_PORT=3000

# =============================================================================
# UI Configuration
# =============================================================================
# The UI container generates /config.js from this value at runtime.
# Default to relative /api and let Nginx proxy to the agent.
UI_API_BASE_URL=/api
